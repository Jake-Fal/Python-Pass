{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNelphz3moEDTpzdBixJ725",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jake-Fal/Python-Pass/blob/main/Python_Pass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input If statement & determining even or odd"
      ],
      "metadata": {
        "id": "qiZrlgYT2eA_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmpGN5Jf1xXG"
      },
      "outputs": [],
      "source": [
        "x = int(input(\"Enter a number\"))\n",
        "if x > 10:\n",
        "  if x % 2 == 0:\n",
        "    print(str(x) + \" is greater than 10 and is even\")\n",
        "  else:\n",
        "    print(str(x) + \" is greater than 10 and is odd\")\n",
        "else:\n",
        "  if x % 2 == 0: #nested if, % = remainder\n",
        "    print(str(x) + \" is not greater than 10 and is even\")\n",
        "  else:\n",
        "    print(str(x) + \" is not greater than 10 and is odd\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loops"
      ],
      "metadata": {
        "id": "zFLFELJZ74AV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For\n",
        "for grade in grades:\n",
        "  grade += 5 \n",
        "  newGrade.append(grade)#replace old grade\n",
        "print(newGrade)\n",
        "\n",
        "for col in df:\n",
        "  print(col, \": \", df[col].dtype) #display all col data types in df\n",
        "#While\n",
        "outsideTemp = 65\n",
        "\n",
        "while outsideTemp < 70:\n",
        "  print(\"It's\", outsideTemp, \"degrees. Turn heater on\")\n",
        "  outsideTemp += 1"
      ],
      "metadata": {
        "id": "J3F8Fafr75fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataframes"
      ],
      "metadata": {
        "id": "HVkDvyie9tMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df2 = pd.read_csv('http://www.ishelp.info/data/insurance.csv')\n",
        "df2.head()\n",
        "#OR\n",
        "data=[['Harry Potter', 'Gryfinndor', 11, 'Male', 'Half-blood'], ['Hermione Granger','Gryffindor', 11, 'Female', 'Muggle-born'], \n",
        "     ['Draco Malfoy','Slytherin', '11', 'Male', 'Pure-blood'], ['Severus Snape','Slytherin', 31, 'Male', 'Half-blood'],\n",
        "     ['Rubeus Hagrid','Gryffindor', 63, 'Male', 'Half-Giant']]\n",
        "df = pd.DataFrame(data, \n",
        "                  columns=['Name','House', 'Age', 'Gender', 'BloodStatus']) \n",
        "df.set_index('Name', inplace=True) # need to set (identity) the index name\n",
        "\n",
        "df['House'] #return column with index\n",
        "\n",
        "for house in df.House:\n",
        "  print(house) #return column w/o index\n",
        "\n",
        "df.iloc[0] #return based on range index\n",
        "df.loc['Harry Potter'] #return based on label index\n",
        "\n",
        "df.iat[0,3] #return range value\n",
        "df.at['Harry Potter', 'BloodStatus'] #return laabel value\n",
        "df.at['Hermione Granger', 'BloodStatus'] = 'Muggle-born' #update/correct value\n",
        "\n",
        "\n",
        "df.loc['Minerva Mcgonagall'] = [\"Gryfinndor\", 70, 'Female', 'Half-blood'] #add row\n",
        "#OR\n",
        "nevilleLongbottomList = [\"Gryfinndor\", 11, \"Male\", \"Pure-blood\"]\n",
        "df.loc['Neville Longbottom'] = nevilleLongbottomList\n",
        "\n",
        "#add hairColor to the end of the df\n",
        "hairColor = ['Brown', 'Brown', 'Blond', 'Black', 'Black']\n",
        "df[\"Hair Color\"] = hairColor\n",
        "\n",
        "#OR\n",
        "eyeColor = ['Green', 'Brown', 'Blue', 'Brown', 'Brown'] #specific  location for column\n",
        "df.insert(4, 'Eye Color', eyeColor)\n",
        "\n",
        "name_df.merge(house_df) #merge on similar column, ()adds on end\n",
        "\n",
        "#OR\n",
        "name_df = pd.DataFrame({'Name':['Harry Potter', 'Severus Snape', 'Hermione Granger', 'Albus Dumbledore', 'Luna Lovegood'],\n",
        "                      'MyHouse':['Gryffindor', 'Slytherin', 'Gryffindor', 'Gryffindor', 'Ravenclaw']})\n",
        "house_df = pd.DataFrame({'Color1':['Red', 'Green', 'Blue'], 'Color2':['Gold', 'Silver', 'Bronze'], 'House':['Gryffindor', 'Slytherin', 'Ravenclaw']})\n",
        "name_df.merge(house_df, left_on='MyHouse', right_on='House', copy=False) #add with spec column on left of merge and spec on end\n",
        "\n",
        "#OR\n",
        "df_small = pd.merge(df_small, cancel_df, how='left', left_on='CANCELLATION_CODE', right_on='Code')\n",
        "\n",
        "#Filter/Drop/Sort\n",
        "df.drop(['House', 'Gender'], axis=1, inplace=True)#delete column (erase axis=1 to delete row), if making new df delete inplace\n",
        "\n",
        "filtered_df = df[(df.BloodStatus == 'Half-blood') | (df.BloodStatus == 'Pure-blood')]#filter\n",
        "\n",
        "df.sort_values(by=['Age'], ascending=True, inplace=True) #sort values\n",
        "\n",
        "df.describe()#gen description\n",
        "for col in df:\n",
        "  print(col, \": \", df[col].dtype) #display all col data types\n",
        "pd.api.types.is_numeric_dtype(df.StealsPerGame) #check certain column data type\n",
        "df.AssistsPerGame.nunique()#unique values count\n",
        "df.isna().sum()#missing values count\n",
        "\n",
        "#Converting to and operating on dates\n",
        "df['signup_date'] = pd.to_datetime(df['signup_date']).dt.date\n",
        "\n",
        "df['signup_date'] = pd.to_datetime(df['signup_date'], format = '%Y-%m-%d')\n",
        "df\n",
        "\n",
        "from datetime import datetime\n",
        "EndOfTrialString = '2023-01-01'\n",
        "EndOfTrial = datetime.strptime(EndOfTrialString, '%Y-%m-%d')\n",
        "\n",
        "df['days_in_trial'] = (EndOfTrial - df['signup_date']).dt.days\n",
        "df\n",
        "\n",
        "#Split columns on delimiter\n",
        "df_small[['Dest_city','Dest_name']] = df_small['DEST_CITY_NAME'].str.split(',', expand = True)\n",
        "\n",
        "#Strip empty trailing and leading spaces\n",
        "df['FName'] = df['FName'].str.strip()\n",
        "\n",
        "#Loop through rows to reassign values\n",
        "for row in df.itertuples():\n",
        "        if row[7] >= 2500:\n",
        "          df.loc[row[0], 'total_crimes'] = 'High'\n",
        "        else:\n",
        "          df.loc[row[0], 'total_crimes'] = 'Low'\n",
        "\n",
        "#Loop through rows to group\n",
        "for row in df.itertuples():\n",
        "  if row.age < 20:\n",
        "    df.at[row.Index, 'Age_Group'] = \"Teens\"\n",
        "  elif row.age < 30:\n",
        "    df.at[row.Index, 'Age_Group'] = \"20s\"\n",
        "  elif row.age < 40:\n",
        "    df.at[row.Index, 'Age_Group'] = \"30s\"\n",
        "  elif row.age < 50:\n",
        "    df.at[row.Index, 'Age_Group'] = \"40s\"\n",
        "  elif row.age < 60:\n",
        "    df.at[row.Index, 'Age_Group'] = \"50s\"\n",
        "  else:\n",
        "    df.at[row.Index, 'Age_Group'] = \"60s\"\n",
        "\n",
        "#Data\n",
        "df.mean()\n",
        "df.mode().values[0]\n",
        "df.min()\n",
        "df.max()\n",
        "df.quantile(.25)\n",
        "df.quantile(.75)\n",
        "df.median()\n",
        "df.std() #standard deviation\n",
        "df.skew()\n",
        "df.kurt() #kurtosis describe the degree to which scores cluster in the tails or the peak of a frequency distribution\n",
        "df.info()#shows how many data points are missing for a column\n",
        "df.isnull().sum()#total missing data\n",
        "df = df.dropna(axis = 1, thresh=50) #delete columns with thresh or more missing values\n",
        "df.dropna(axis = 1, inplace = True) # delete all columnss with missing data\n",
        "df.dropna(subset=['charges'], inplace = True) #delete row with missing data\n",
        "df.children.fillna(0, inplace = True) #fill na data with certain value\n",
        "df['smoker']=df['smoker'].fillna(df['smoker'].mode()[0]) #fill na data with a stat (can be used with mean, median ...)\n",
        "\n",
        "#Outliers\n",
        "outliers = pd.DataFrame(columns=['min', 'count below', 'max', 'count above'])\n",
        "for col in dfInsurance:\n",
        "  if pd.api.types.is_numeric_dtype(dfInsurance[col]):  \n",
        "    q1 = dfInsurance[col].quantile(.25)\n",
        "    q3 = dfInsurance[col].quantile(.75)\n",
        "    IQR = q3 - q1\n",
        "    lower_bound = q1 - (1.5 * IQR)\n",
        "    upper_bound = q3 + (1.5 * IQR)   \n",
        "    outliers.loc[col] = (lower_bound, dfInsurance[col][dfInsurance[col] < lower_bound].count(), upper_bound, dfInsurance[col][dfInsurance[col] > upper_bound].count())\n",
        "outliers\n",
        "outlierStats(dfMPG)#show a table of how many above and below outliers \n",
        "#Function that can return all outliers for spec col\n",
        "\n",
        "def outlierDF(df, col):\n",
        "  q1 = df[col].quantile(.25)\n",
        "  q3 = df[col].quantile(.75)\n",
        "  IQR = q3 - q1\n",
        "  lower_bound = q1 - (1.5 * IQR)\n",
        "  upper_bound = q3 + (1.5 * IQR)\n",
        "  dfOutliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
        "  return(dfOutliers)\n",
        "outlierDF(dfMPG, 'Acceleration')\n",
        "\n",
        "#Box Plot to show outliers\n",
        "def boxplot(df, col):\n",
        "  title = col + ' Box Plot'\n",
        "  plt.title(title)\n",
        "  sns.boxplot(x=df[col], palette=\"Blues\", width=0.2)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "t-pKAOig9vLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions"
      ],
      "metadata": {
        "id": "c5lJg3nwEOKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_NBA_Info (df, colName, filter):\n",
        "  result = df[df[colName] == filter]\n",
        "  return result\n",
        "\n",
        "get_NBA_Info (df, \"Year\", 2012)\n",
        "\n",
        "#ANOVA\n",
        "def calculateANOVA(df, feature, label):\n",
        "  from scipy import stats\n",
        "  groups = df[feature].unique()  \n",
        "  group_labels = []             \n",
        "  for g in groups:                \n",
        "    group_labels.append(df[df[feature] == g][label])  \n",
        "  f, p=stats.f_oneway(*group_labels) \n",
        "  return print('F: ' + str(round(f, 4)) + '\\np: ' + str(round(p, 4)))\n",
        "calculateANOVA(dfInsurance,'smoker','charges')\n",
        "\n",
        "#Box &/ Hist w/ Stats\n",
        "def univariate_charts(df, box=True, hist=True, stats=True, save=False, save_path=\"\"):\n",
        "  import pandas as pd\n",
        "  import matplotlib.pyplot as plt\n",
        "  import seaborn as sns\n",
        "  for col in df:  \n",
        "    if pd.api.types.is_numeric_dtype(df[col]):\n",
        "      if box and hist:\n",
        "        f, (ax_box, ax) = plt.subplots(2, sharex=True, gridspec_kw={'height_ratios': (.15,.65)})\n",
        "        sns.set(style = 'ticks')\n",
        "        flierprops = dict(marker = 'o', markersize = 4, markerfacecolor = 'none', linestyle = 'none', markeredgecolor = 'gray')\n",
        "        sns.boxplot(x = df[col], ax=ax_box, fliersize=4, width=.50,linewidth=1, flierprops=flierprops)\n",
        "        sns.histplot(x=df[col], ax=ax)\n",
        "        ax_box.set(yticks=[])\n",
        "        ax_box.set(xticks=[])\n",
        "        ax_box.set_xlabel('')\n",
        "        sns.despine(ax=ax)\n",
        "        sns.despine(ax=ax_box, left = True, bottom = True)\n",
        "        ax_box.set_title(col, fontsize=14)\n",
        "      elif box and not hist:\n",
        "        flierprops = dict(marker = 'o', markersize = 4, markerfacecolor = 'none', linestyle = 'none', markeredgecolor = 'gray')\n",
        "        ax=sns.boxplot(x = df[col], fliersize=4, saturation = .5, width=.50,linewidth=1, flierprops=flierprops)\n",
        "        ax_box.set(yticks=[])\n",
        "        ax_box.set(xticks=[])\n",
        "        ax_box.set_xlabel('')\n",
        "        ax.set_title(col)\n",
        "        sns.despine(ax=ax, left=True, bottome=True)\n",
        "      elif not box and hist:\n",
        "        ax = sns.histplot(x=df[col])\n",
        "        sns.despine(ax=ax)\n",
        "        ax.set_title(col, fontsize=14)\n",
        "      if stats:\n",
        "        text = 'Count: ' + str(df[col]) + '\\n'\n",
        "        text += 'Unique: ' + str(round(df[col].nunique(), 2)) + '\\n'\n",
        "        text += 'Data Type: ' + str(df[col].nunique()) + '\\n'\n",
        "        text += 'Missing: ' + str(round(df[col].isnull().sum(), 2)) + '\\n'\n",
        "        text += 'Mode: ' + str(df[col].mode().values[0]) + '\\n'\n",
        "        text += 'Min: ' + str(round(df[col].min(), 2)) + '\\n'\n",
        "        text += '25%: ' + str(round(df[col].quantile(.25), 2)) + '\\n'\n",
        "        text += 'Median: ' + str(round(df[col].median(), 2)) + '\\n'\n",
        "        text += '75%: ' + str(round(df[col].quantile(.75), 2)) + '\\n'\n",
        "        text += 'Max: ' + str(round(df[col].max(), 2)) + '\\n'\n",
        "        text += 'Std Dev: ' + str(round(df[col].std(), 2)) + '\\n'\n",
        "        text += 'Mean: ' + str(round(df[col].mean(), 2)) + '\\n'\n",
        "        text += 'Skew: ' + str(round(df[col].skew(), 2)) + '\\n'\n",
        "        text += 'Kurt: ' + str(round(df[col].kurt(), 2)) + '\\n'\n",
        "        ax.text(.9,.25,text,fontsize=10,transform=plt.gcf().transFigure)\n",
        "\n",
        "#Scatter Plot/Join Plot w lin reg:\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "for col in df_clean:\n",
        "  if col != 'cnt':\n",
        "    if pd.api.types.is_numeric_dtype(df_clean[col]):\n",
        "      r, p = stats.pearsonr(df_clean[col],df.cnt) #not necessary but one example of text to put on graph\n",
        "      text = \"p-value: \"+ str(round(p,3)) + '\\n' +'r-value: ' + str(round(r,3))\n",
        "      ax = sns.jointplot(data=df_clean, x=col, y=\"cnt\", kind=\"reg\")\n",
        "      ax.fig.suptitle(f'{col} & Cnt')\n",
        "      ax.fig.tight_layout()\n",
        "      ax.fig.subplots_adjust(top=0.95)\n",
        "      ax.fig.text(1,0.8, text, fontsize=12, transform=plt.gcf().transFigure);"
      ],
      "metadata": {
        "id": "3-BnfXRvEPtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Biv Stats --\n",
        "P-Value < 0.05 hypothesis is rejected, is statistically significant\n",
        "R-Value = effect size/correlation, 0-.29(weak), .3 - .49(med), .5 - 1 (strong), positive/negative does not matter. \n",
        "R^2-Value = the percentage of the variance in the dependent variable that the independent variable(s) explain, higher R Square represents smaller differences between the observed data and the fitted (predicted) values, https://statisticsbyjim.com/regression/interpret-r-squared-regression/"
      ],
      "metadata": {
        "id": "6LR73umJJHMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Numerical/Numerical\n",
        "\n",
        "from scipy import stats\n",
        "corr = stats.pearsonr(df.Acceleration, df.MPG)#correlation and statistical significance\n",
        "print('r: ' + str(round(corr[0], 4))) \n",
        "print('p-value:' + str(round(corr[1], 4)))\n",
        "#OR\n",
        "df.corr()['MPG'].sort_values()#sorts correlated values(R-Value) from low to high\n",
        "#OR\n",
        "corr_df = pd.DataFrame(columns = ['r', 'p-value']) #shows R and P-Values in table\n",
        "for col in df:\n",
        "  if pd.api.types.is_numeric_dtype(df[col]):\n",
        "    r, p = stats.pearsonr(df[col], df.MPG)\n",
        "    corr_df.loc[col] = [round(r, 3), round(p,6)]\n",
        "corr_df.sort_values(by=['r'], ascending=False)\n",
        "\n",
        "import seaborn as sns\n",
        "correlation_mat = df.corr()#correlation matrix (only numerical)\n",
        "sns.heatmap(correlation_mat, annot = True)\n",
        "\n",
        "import numpy as np\n",
        "model = np.polyfit(df.Weight, df.MPG, 1) #linear reg equation with prediction\n",
        "predict = np.poly1d(model)\n",
        "predict(3400)\n",
        "#R^2 Score\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score(df.MPG, predict(df.Weight))\n",
        "\n",
        "#VIF - test for multicollinearity(discounts MLR(multiple linear regression)), a score above 5 is considered high\n",
        "from sklearn.linear_model import LinearRegression\n",
        "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64'] #select only numeric columns\n",
        "newdf = df.select_dtypes(include=numerics)\n",
        "newdf = newdf.drop(['MPG'], axis = 1) #drop the label\n",
        "newdf.head()\n",
        "vif_dict = {} # initialize dictionaries\n",
        "for col in newdf: # form input data for each exogenous variable\n",
        "  y =  newdf[col]\n",
        "  X = newdf.drop(columns=[col])\n",
        "  r_squared = LinearRegression().fit(X, y).score(X, y) # extract r-squared from the fit\n",
        "  vif = 1/(1 - r_squared)# calculate VIF\n",
        "  vif_dict[col] = vif\n",
        "pd.DataFrame({'VIF': vif_dict})\n",
        "\n",
        "#Heteroscedasticity\n",
        "from statsmodels.compat import lzip\n",
        "import statsmodels.stats.api as sms\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "# ----------------- STEP 1 -------------------------------\n",
        "#loop through the columns in the dataframe. If the column datatype is NOT numeric, generate dummy code variables for those categorical variables.\n",
        "#Dummy code variables break out a categorical value into multiple variables and assign 0 and 1s to those variables. It makes a categorical variable numeric.\n",
        "\n",
        "for col in df: \n",
        "  if not pd.api.types.is_numeric_dtype(df[col]): \n",
        "    df = df.join(pd.get_dummies(df[col], prefix=col, drop_first=True))\n",
        "\n",
        "# ----------------- STEP 2 -------------------------------\n",
        "#Create your y and X variables. The y variable will hold the label. \n",
        "# The X variable will hold all numeric variables (will drop the categorical variables but that's okay because the categorical variables have dummy variables that are numeric (have 0 and 1s))\n",
        "# The X variable will also be assigned a constant of 1 (will allow there to be a y-intercept when creating the linear regression equation ) and will drop the label.\n",
        "\n",
        "y = df['charges']\n",
        "X = df.select_dtypes(np.number).assign(const=1)\n",
        "X = X.drop(columns=['charges'])\n",
        "\n",
        "# ----------------- STEP 3 -------------------------------\n",
        "#Create the OLS (linear regression) model. Pass in the y and X.\n",
        "\n",
        "model = sm.OLS(y,X).fit()\n",
        "\n",
        "# ----------------- STEP 4 -------------------------------\n",
        "#Calculate the breuschpagan test. Pass in the residuals (difference between the actual/observed value and the predicted value)\n",
        "#Also pass in the X values (represented by the model.model.exog. Exog is another word for X or independent variables)\n",
        "bp_data = sms.het_breuschpagan(model.resid, model.model.exog)\n",
        "\n",
        "# ----------------- STEP 5 -------------------------------\n",
        "#create a dataframe that holds just the Lagrange multiplier statistic and the p-value\n",
        "#create a list (names) that holds the statistic and the p-value\n",
        "#zip the bp_data and the names list up to create a dictionary\n",
        "#Use the dictionary to create a dataframe where the index is 'Breusch-Pagan Values'\n",
        "names = ['Lagrange multiplier statistic', 'p-value']\n",
        "bp_data_dict= dict(lzip(names, bp_data))\n",
        "bp_df = pd.DataFrame(bp_data_dict, index = ['Breusch-Pagan Values'])\n",
        "\n",
        "bp_df\n",
        "\n",
        "#Cat-Num\n",
        "#T-Test used to determine whether or not the means of two populations are equal, returns P-Value and T-Value\n",
        "from scipy import stats\n",
        "male = df[df['sex'] == 'male']\n",
        "female = df[df['sex'] == 'female']\n",
        "t, p = stats.ttest_ind(male.charges, female.charges)\n",
        "print(\"t: \" + str(round(t, 3)))\n",
        "print(\"p: \" + str(round(p, 3)))\n",
        "\n",
        "#ANOVA multiple averages being compared, returns P-Value and F-Value\n",
        "\n",
        "#Loop\n",
        "groups = df['region'].unique() \n",
        "group_labels = []               \n",
        "for g in groups:              \n",
        "  group_labels.append(df[df['region'] == g]['charges']) \n",
        "f, p =  stats.f_oneway(*group_labels) #group_labels is a shortcut way of listing out each of the regions. \n",
        "print('F: ' + str(round(f, 4)))\n",
        "print('p: ' + str(round(p, 4)))\n",
        "\n",
        "#Function\n",
        "def calculateANOVA(df, feature, label):\n",
        "  from scipy import stats\n",
        "  groups = df[feature].unique()  \n",
        "  group_labels = []             \n",
        "  for g in groups:                \n",
        "    group_labels.append(df[df[feature] == g][label])  \n",
        "  f, p=stats.f_oneway(*group_labels) \n",
        "  return print('F: ' + str(round(f, 4)) + '\\np: ' + str(round(p, 4)))\n",
        "calculateANOVA(dfInsurance,'smoker','charges')\n",
        "\n",
        "#Tukey's Test post-hoc (after Anova) shows P-Values between all possible combos of data\n",
        "from scipy.stats import f_oneway\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "tukey = pairwise_tukeyhsd(endog=df['charges'],\n",
        "                          groups=df['region'],\n",
        "                          alpha=0.05)\n",
        "print(tukey)\n",
        "\n",
        "#Pivot Test - table with average of all data combos\n",
        "print(df.groupby(['region', 'sex']).mean()['charges'])\n",
        "\n",
        "#Cat/Cat\n",
        "#Chi-Square - used to determine whether there is a relationship between two categorical variables, is a measure of effect size and ranges from 0 to infinity. The higher the chi-square, the stronger the effect size. \n",
        "import pandas as pd\n",
        "crosstab = pd.crosstab(index = df['Purchased Bike'], columns = df['Region'])\n",
        "\n",
        "x, p, dof, expected_values = chi2_contingency(crosstab)\n",
        "\n",
        "print('chi-square: ' + str(round(x,4)))\n",
        "print('p-value: ' + str(round(p, 4)))\n",
        "\n",
        "#RMSE & MAE w/ r^2\n",
        "#MAE: the mean absolute difference between the predicted values and the actual values in the dataset. \n",
        "#Our predicted charges are, on average,about 9,015 dollars away from the actual charges. The lower the number, the better the model.\n",
        "\n",
        "#RMSE: the square root of the averate squared difference between the predicted values and the actual values in a dataset. \n",
        "#The lower the RMSE, the better the model.\n",
        "import numpy as np\n",
        "residuals = np.array(df[label]) - np.array(results1.fittedvalues)\n",
        "rmse = np.sqrt(sum((residuals**2)) / len(df[label]))\n",
        "\n",
        "mae = np.mean(abs(np.array(df[label]) - np.array(results1.fittedvalues)))\n",
        "\n",
        "metrics  = \"R-squared:\\t\" + str(round(results1.rsquared, 4)) + \"\\n\"\n",
        "metrics += \"RMSE:\\t\\t\" + str(round(rmse, 4)) + \"\\n\"\n",
        "metrics += \"MAE:\\t\\t\" + str(round(mae, 4)) + \"\\n\"\n",
        "metrics += \"Label mean:\\t\" + str(round(np.mean(df[label]), 4))\n",
        "\n",
        "print(metrics)\n",
        "\n",
        "#MLR num&cat\n",
        "#R-Square: Coefficient of determination. The proportion of variance in charges (y variable) that can be explained by the x variables. \n",
        "#12% of the variance in charges can be explained by age, bmi, and children. Ranges typically from 0-1 (although can go down to -1). \n",
        "#Typically, want a higher number, but there is no cut-off on what is considered 'high'. Need to compare the r-square against another similar model.\n",
        "\n",
        "#Prob (F-statistic): Essentially the p-value for the entire model. If the p-value is below 0.05, the entire model is statistically significant. \n",
        "#In this case, age, bmi, and the number of children have a statistically significant association with the response variable.\n",
        "\n",
        "#Coef: the coefficient strength. For example, for every year increase in age, the predicted charges goes up 239.99 dollars. \n",
        "#Especially in next semester's class, you will use these coefficients to create a calculator to predict insurance charges. \n",
        "#You can use these coefficients and the cont (the y-intercept) to make a linear regression equation. If you know the age, bmi, and children, you can predict the charges.\n",
        "\n",
        "#charges = -6916 + (239 * age) + (332 * bmi) + (542 * # of children)\n",
        "\n",
        "#p>|t|: the individual coefficient p-values. If the p-value is less than 0.05, that independent variable is statistically significant. \n",
        "#If an independent variable is NOT statistically significant, you may end up deciding to remove it from the model\n",
        "\n",
        "#scaling before MLR (min-max norm)\n",
        "from sklearn import preprocessing\n",
        "\n",
        "#create dummy codes \n",
        "df_dummy3 = df.copy() #create a copy of the dataframe so you aren't adding dummy codes to the original dataframe\n",
        "\n",
        "label = 'charges'\n",
        "\n",
        "for col in df_dummy3:\n",
        "  if not pd.api.types.is_numeric_dtype(df_dummy3[col]): #if the value is not numeric, it must be categorical so we need to create dummy variables\n",
        "    df_dummy3 = df_dummy3.join(pd.get_dummies(df_dummy3[col], prefix=col, drop_first=True)) #get_dummy creates the dummy codes for us. It will technically do dummy codes for all the values, since we need one less than the total values, we will drop the first one\n",
        "\n",
        "df_num = df_dummy3.select_dtypes(np.number)\n",
        "\n",
        "df_minmax = pd.DataFrame(preprocessing.MinMaxScaler().fit_transform(df_num), columns=df_num.columns)\n",
        "df_minmax.head()\n",
        "\n",
        "#numerical MLR\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "label = 'charges'\n",
        "y = df[label]\n",
        "X = df.select_dtypes(np.number).assign(cont=1) #drop all categorical features\n",
        "X = X.drop(columns=[label])\n",
        "\n",
        "#run the multiple linear regression model\n",
        "model1 = sm.OLS(y, X)\n",
        "results1 = model1.fit()\n",
        "\n",
        "print(results1.summary())\n",
        "\n",
        "#num/cat MLR\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "df_dummy2 = df.copy() #create a copy of the dataframe so you aren't adding dummy codes to the original dataframe\n",
        "\n",
        "label = 'charges'\n",
        "\n",
        "for col in df_dummy2:\n",
        "  if not pd.api.types.is_numeric_dtype(df_dummy2[col]): #if the value is not numeric, it must be categorical so we need to create dummy variables\n",
        "    df_dummy2 = df_dummy2.join(pd.get_dummies(df_dummy2[col], prefix=col, drop_first=True)) #get_dummy creates the dummy codes for us. It will technically do dummy codes for all the values, since we need one less than the total values, we will drop the first one\n",
        "\n",
        "y = df_dummy2[label]\n",
        "X = df_dummy2.select_dtypes(np.number).assign(const=1)\n",
        "X = X.drop(columns=[label])\n",
        "\n",
        "model2 = sm.OLS(y,X)\n",
        "results2 = model2.fit()\n",
        "print(results2.summary())\n",
        "\n",
        "#More Eval Metrics\n",
        "y_test_dummies = pd.get_dummies(y_test)\n",
        "y_pred_dummies = pd.get_dummies(y_pred)\n",
        "\n",
        "# Accuracy  = (true positives + true negatives) / (total cases); the percentage of predictions the model got right\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "accuracy2 = (tp + tn) / (tp + tn + fp + fn)\n",
        "print(\"Accuracy: \" + str(round(accuracy, 4)))\n",
        "print(\"Accuracy2: \" + str(round(accuracy2, 4))) \n",
        "\n",
        "# Precision = (true positives / (true positives + false positives)); what proportion of predicted positive identifications(no) where actually correct\n",
        "precision = metrics.precision_score(y_test_dummies.yes, y_pred_dummies.yes)\n",
        "precision2 = tp / (tp + fp)\n",
        "print(\"precision: \" + str(round(precision, 4)))\n",
        "print(\"precision2: \" + str(round(precision2, 4))) \n",
        "\n",
        "# Recall    = (true positives / (true positives + false negatives)); What proportion of actual positives were identified correctly? \n",
        "recall = metrics.recall_score(y_test_dummies.yes, y_pred_dummies.yes)\n",
        "recall2 = tp/(tp+fn)\n",
        "print(\"recall: \" + str(round(recall, 4)))\n",
        "print(\"recall2: \" + str(round(recall2, 4))) \n",
        "\n",
        "# F1        = (2 * (precision * recall) / (precision + recall))\n",
        "f1 = metrics.f1_score(y_test_dummies.yes, y_pred_dummies.yes)\n",
        "f12 = (2 * (precision * recall) / (precision + recall))\n",
        "print(\"f1: \" + str(round(f1, 4)))\n",
        "print(\"f12: \" + str(round(f12, 4))) \n",
        "\n"
      ],
      "metadata": {
        "id": "MCzy8lcaJG7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizations"
      ],
      "metadata": {
        "id": "gnD8xGtcE1ZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Univariate\n",
        "#Histogram\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "from importlib import reload\n",
        "plt=reload(plt)\n",
        "Eaverage = str(round(df[df['Conference'] == 'Eastern'].PointsPerGame.mean(),2))\n",
        "Estdev = str(round(df[df['Conference'] == 'Eastern'].PointsPerGame.std(),2))\n",
        "Waverage = str(round(df[df['Conference'] == 'Western'].PointsPerGame.mean(),2))\n",
        "Wstdev = str(round(df[df['Conference'] == 'Western'].PointsPerGame.std(),2))\n",
        "text = 'Eastern Confernce \\n Average: ' + Eaverage + '\\n Standard Dev.: ' + Estdev + '\\n \\n Western Conference \\n Average: ' + Waverage + '\\n Standard Dev: ' + Wstdev text = 'Skew: ' + skew\n",
        "plt.text(.15, .60, text, fontsize = 10, transform=plt.gcf().transFigure)\n",
        "plt.title('Points Per Game')\n",
        "sns.histplot(df, x = 'PointsPerGame', hue = 'Conference', palette='deep'); #add semicolon or plt.show() to get rid of above text\n",
        "\n",
        "#Boxplot\n",
        "EMedian = str(round(df[df['Conference'] == 'Eastern'].StealsPerGame.median(),2))\n",
        "WMedian = str(round(df[df['Conference'] == 'Western'].StealsPerGame.median(),2))\n",
        "text = 'Eastern Median: ' + EMedian + '\\n Western Median: ' + WMedian\n",
        "plt.text(.65,.50,text, fontsize=10, transform=plt.gcf().transFigure)\n",
        "plt.title('Steals Per Game')\n",
        "sns.boxplot(x=df.StealsPerGame, y=df.Conference, palette=\"Blues\", width=0.2); #add semicolon or plt.show() to get rid of above text\n",
        "#Box Plot to show outliers\n",
        "def boxplot(df, col):\n",
        "  title = col + ' Box Plot'\n",
        "  plt.title(title)\n",
        "  sns.boxplot(x=df[col], palette=\"Blues\", width=0.2)\n",
        "\n",
        "#Bivariate\n",
        "#Num-Num\n",
        "#Scatter Plot\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "from sklearn.metrics import r2_score\n",
        "df = pd.read_csv('https://www.dropbox.com/s/vdnsxihhn7pgdtq/mpg.csv?dl=1')\n",
        "plt.scatter(df.Weight, df.MPG) #can do multiple on same graph, define different dfs\n",
        "plt.xlabel('Weight')\n",
        "plt.ylabel('MPG')\n",
        "plt.title('Weight and MPG')\n",
        "plt.show()\n",
        "corr = stats.pearsonr(df.Weight, df.MPG)\n",
        "model = np.polyfit(df.Weight, df.MPG, 1)\n",
        "predict = np.poly1d(model)\n",
        "r2 = r2_score(df.MPG, predict(df.Weight))\n",
        "print('r: ' + str(round(corr[0], 4))) \n",
        "print('p-value:' + str(round(corr[1], 6)))\n",
        "print('r2:' + str(round(r2,4)))\n",
        "print('y = ' + str(round(model[0],3)) + ' * x + ' + str(round(model[1],3)))\n",
        "\n",
        "#Probability Plot Multivariate Normality\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "model = sm.OLS(y, X)\n",
        "results = model.fit()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "_,(_,_,r) = stats.probplot(results.resid, plot=ax, fit=True)\n",
        "print(round(r**2,3))\n",
        "\n",
        "#Lin Reg on Scatter Plot\n",
        "x_lin_reg = range(1500,df.Weight.max())#Get the range of the x axis (start at the min x value you want shown and go to the max weight). \n",
        "y_lin_reg = predict(x_lin_reg)\n",
        "plt.plot(x_lin_reg, y_lin_reg, c = 'r')\n",
        "plt.show()\n",
        "\n",
        "#Joint Plot\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "r, p = stats.pearsonr(df.Weight,df.Price) #not necessary but one example of text to put on graph\n",
        "text = \"p-value: \"+ str(round(p,3)) + '\\n' +'r-value: ' + str(round(r,3))\n",
        "ax = sns.jointplot(data=df, x=\"Weight\", y=\"Price\", kind=\"reg\")\n",
        "ax.fig.suptitle('Weight and Price')\n",
        "ax.fig.tight_layout()\n",
        "ax.fig.subplots_adjust(top=0.95)\n",
        "ax.fig.text(1,0.8, text, fontsize=12, transform=plt.gcf().transFigure);\n",
        "\n",
        "#4D Scatter\n",
        "import plotly.express as px\n",
        "fig = px.scatter_3d(df, x = 'Weight', y = 'MPG', z = 'Horse_Power', color = 'Model_Year', size_max = 20,\n",
        "opacity = .5, hover_name='Cars' )\n",
        "fig.show()\n",
        "\n",
        "#Cat-Num\n",
        "#Bar Plots\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "df = pd.read_csv('https://www.ishelp.info/data/insurance.csv')\n",
        "sns.barplot(x = 'region', y = 'charges', hue = 'smoker', data = df)\n",
        "plt.title('Insurance Charges by Region and Smoker')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "#Cat-Cat\n",
        "#Cat Plot\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "viz = sns.catplot(x = \"Education\", kind=\"count\", palette = \"Blues\", data=df, order=['Partial High School', 'High School', 'Partial College', 'Bachelors', 'Graduate Degree'],\n",
        "                  hue = \"Marital Status\", col=\"Home Owner\");\n",
        "\n",
        "plt.title(\"Education Count\")\n",
        "\n",
        "viz.set_xticklabels(rotation=25);\n",
        "\n",
        "#countplot\n",
        "df_OgUt = df_small[(df_small.Grouping_Origin == 'SLC') | (df_small.Grouping_Origin == 'UT Non-SLC')]\n",
        "sns.countplot(x = 'Description', hue='Grouping_Origin', data = df_OgUt)\n",
        "plt.title('Cancelled Flights')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "#Heatmap Crosstab\n",
        "#Observed Counts\n",
        "crosstab = pd.crosstab(index = df['Purchased Bike'], columns = [df['Home Owner'], df['Marital Status']])\n",
        "\n",
        "sns.heatmap(crosstab, annot=True, fmt='d') #fmt='d' outputs the results as a decimal integer (base 10)\n",
        "\n",
        "#Expected Counts\n",
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "from scipy.stats import chi2\n",
        "\n",
        "crosstab = pd.crosstab(index = df['Purchased Bike'], columns = df['Region'])\n",
        "\n",
        "x, p, dof, expected_values = chi2_contingency(crosstab)\n",
        "\n",
        "ev_df = pd.DataFrame(np.rint(expected_values).astype('int64'), columns=crosstab.columns, index = crosstab.index )\n",
        "\n",
        "sns.heatmap(ev_df, annot=True, fmt='d', cmap='coolwarm')\n",
        "\n",
        "plt.title('Expected Values of Purchased Bike and Region')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "#Decision Tree\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "\n",
        "for col in df:\n",
        "  if not pd.api.types.is_numeric_dtype(df[col]):\n",
        "    df = df.join(pd.get_dummies(df[col], prefix=col))\n",
        "\n",
        "y = df['y'] # Label\n",
        "X = df.drop(columns=['y', 'y_no', 'y_yes']) # Features\n",
        "X = X.select_dtypes(np.number)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345) # 70% training and 30% test\n",
        "\n",
        "# Create Decision Tree classifer object\n",
        "clf = DecisionTreeClassifier(random_state=12345)\n",
        "  \n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train,y_train)\n",
        "  \n",
        "# Predict the labels for test dataset\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# View the predicted versus actual in a DataFrame\n",
        "\n",
        "output_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred,})\n",
        "output_df.head(50)\n",
        "\n",
        "#Visualize Tree\n",
        "#!pip install graphviz\n",
        "#!pip install pydotplus\n",
        "from sklearn.tree import export_graphviz\n",
        "from six import StringIO \n",
        "from IPython.display import Image  \n",
        "import pydotplus\n",
        "\n",
        "dot_data = StringIO()\n",
        "export_graphviz(clf, out_file=dot_data, \n",
        "                filled=True, rounded=True, \n",
        "                special_characters=True, feature_names = X.columns,class_names=['no', 'yes'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "graph.write_png('bank.png')\n",
        "Image(graph.create_png())\n",
        "\n",
        "#Classification Matrix\n",
        "from sklearn import metrics\n",
        "from matplotlib import pyplot as plt\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "cm_display = metrics.ConfusionMatrixDisplay(cm, display_labels=['no', 'yes'])\n",
        "cm_display.plot(values_format='d')\n",
        "plt.show()\n",
        "\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "print('tn: ' + str(tn))\n",
        "print('fp: ' + str(fp))\n",
        "print('fn: ' + str(fn))\n",
        "print('tp: ' + str(tp))"
      ],
      "metadata": {
        "id": "7vncBg1CE3NA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Web Scraping"
      ],
      "metadata": {
        "id": "TVYb2HsEJ2yO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup #from the bs4 (BeautifulSoup 4) library, import the BeautifulSoup module \n",
        "import requests\n",
        "#specify which website to use in the url variable\n",
        "url= 'https://webscraper.io/test-sites/e-commerce/allinone/computers/laptops' #assign the url that we want to web scrape, to the 'url' variable\n",
        "\n",
        "#request the HTML from the url variable\n",
        "req = requests.get(url) #using the request library, we are getting or retrieving the HTML from the specified url. This is a common HTTP method. \n",
        "\n",
        "print(req) # a 200 OK response means the request was successful. 404 NOT FOUND means the resource we were looking for was not found.\n",
        "#get the text within the request\n",
        "html = req.text #.text gets all the text within the request. All this HTML text is assigned to the html variable\n",
        "\n",
        "print(html) #print the html variable to see the all the HTML from the website specified in the url variable\n",
        "#create a BeautifulSoup object based off the markup text of the html\n",
        "soup = BeautifulSoup (html, 'html.parser') #pass the BeautifulSoup object the markup text (the html variable) and the html.parser. The new BeautifulSoup object is called soup and it will make the text readable\n",
        "\n",
        "print(soup) #print the object 'soup' which contains the beautified HTML\n",
        "#find all the product descriptions\n",
        "soup.findAll('p', {'class': 'description'}) #finds all p tags with a class of 'description'. Returns a list.\n",
        "#find all the product titles \n",
        "soup.findAll('a', {'class': 'title'}) #finds all 'a' tags with a class of 'title'. Returns a list.\n",
        "#find all the product prices\n",
        "soup.findAll('h4', {'class': 'pull-right price'}) #find all the h4 tags with a class of 'pull-right price'. Returns a list. \n",
        "#find all the products\n",
        "products = soup.findAll('div', {'class': 'thumbnail'}) #finds all div tags with a class of 'thumbnail'\n",
        "print(products)\n",
        "#for each product, get the title, description, price\n",
        "import pandas as pd\n",
        "data = []\n",
        "for p in products:\n",
        "  title = p.find('a', {'class': 'title'})['title'] #for each product, find the p tag with a class of title. Get only the title attribute within the 'a' tag. \n",
        "  description = p.find('p', {'class': 'description'}).text.strip() # for each product, find the p tag with a class of 'description'. Get only the text and strip away white space.\n",
        "  price = p.find('h4', {'class': 'pull-right price'}).text.strip() # for each product, find the h4 tage with a class pf 'pull-right price'. Get only the text and strip away white space.\n",
        "  data.append((title, description, price)) #add/append title, description, and price to the Data \n",
        "df = pd.DataFrame(data, columns=['Title', 'Description', 'Price'])\n",
        "df"
      ],
      "metadata": {
        "id": "nm97SU8PJwJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning"
      ],
      "metadata": {
        "id": "-_Qo2vVX7-EV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace acronyms our misspellings\n",
        "toDrop = ['NOLA']\n",
        "\n",
        "df.loc[df.branch.isin(toDrop), 'branch'] = 'New Orleans'\n",
        "\n",
        "#Compare where the missing values happen per column\n",
        "import missingno as msno\n",
        "\n",
        "msno.matrix(df)"
      ],
      "metadata": {
        "id": "v3hglI8q79dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Formats w/ Lists and Dicts"
      ],
      "metadata": {
        "id": "R9nIKO5W33Ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"I am {age} years old\") #F-string\n",
        "shoppingList = [[\"Apples\", 3, 1.90], [\"Grapes\", 5, 2.04], [\"Bananas\", 8, 1.59]] #Lists\n",
        "print(shoppingList[1]) #print specific\n",
        "shoppingList[4] = \"Wheat Bread\" #edit list\n",
        "shoppingList.insert(3, 'Grapes') #insert list\n",
        "shoppingList.append(\"Oreos\") #add to end\n",
        "shoppingList.remove(\"Oreos\")\n",
        "shoppingList.clear()\n",
        "print(len(shoppingList)) # #of items\n",
        "print(shoppingList.count(\"Apples\")) # #of times spec item is listed\n",
        "shoppingDictionary = {1: 'Apples', 2: 'Bananas', 3: 'Chips'} #dictionary\n",
        "print(priceDictionary['Bananas']) #read spec return for item\n",
        "dictionary.keys() # read all keys\n",
        "dictionary.values() # read all values\n",
        "dictionary.items() # flatten all keys and values into a list and read\n",
        "priceDictionary['Apples'] = 1.50 #update/add\n",
        "print(priceDictionary.pop('Chicken')) #remove\n",
        ".clear() # clear the dictionary\n",
        "print(sorted(priceDictionary.values())) #sort\n",
        "\n"
      ],
      "metadata": {
        "id": "VZxG2i9X31pE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vocab"
      ],
      "metadata": {
        "id": "kgTRjgGG2ifd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "str.isalnum() -> returns true or false depending on whether all string characters are alphabetic or numeric\n",
        "str.isalpha() -> returns true or false depending on whether all string contains are alphabetic\n",
        "str.isdecimal() -> returns true or false depending on whether the string contains all numeric characters with at least one decimal place\n",
        "str.isdigit() -> returns true or false depending on whether the entire string is a valid integer (e.g. 1234 = true, 1234a = false)\n",
        "str.isnumeric() -> returns true or false depending on whether the string can be converted to any type of number (integer or decimal)\n",
        "str.isascii() -> returns true or false depending on whether all string appear in the ASCII table \n",
        "str.islower() -> returns true or false depending on whether all string characters are lowercase alphabetic\n",
        "str.isupper() -> returns true or false depending on whether all string characters are uppercase alphabetic\n",
        "+= -> adding to each value (loop)\n",
        "-= -> subtracting from each value (loop)\n",
        "* -> multiply\n",
        "| -> filtering 'or'\n",
        "& -> filtering 'and'"
      ],
      "metadata": {
        "id": "tmJTclFA3RS3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}